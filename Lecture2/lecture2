% ---------- Титульный слайд -------------
\title{Многомерный анализ данных. Спецкурс.}
\subtitle{Лекция 2. Анализ нечисловых данных}
\author{ДВФУ/БСИ ДВО РАН}% \\ \texttt{kislov@botsad.ru}}
\date{Кислов Д.Е. \\ \today}
\maketitle
% -----------------------------------------

% --------------- слайд 2 -----------------

\begin{frame}
\frametitle{Обработка нечисловых данных. Специфика задач.}

Особенности:
\begin{itemize}
\item<1-> нельзя применять арифметические операции (сложение, вычитание и т.п.)
\item<2-> не всегда просто судить о сходстве объектов
\item<3-> непременимы многие статистические понятия (среднее, дисперсия и т.п.) 
\end{itemize}

\only<4->{
Как обрабатывать:
\begin{itemize}
\item<4-> проблемно-ориентированный подход: иногда можно назначать нечисловым показателям числовые метки
\item<5-> можно работать с таблицами сопряженности признаков
\item<6-> попробовать ввести количественные меры  <<близости>> объектов (учитывая специфику задачи)
\item<7-> оценивать вероятности наличия тех или иных признаков на основе предельных теорем
\end{itemize}}
\end{frame}
% -----------------------------------------


% --------------- слайд 3 -----------------
\def\firstcircle{(0,0) circle (1.5cm)}
\def\secondcircle{(0:2cm) circle (1.5cm)}
\def\rectangle{(-2,-1.6) rectangle (4, 1.6);}

\colorlet{circle edge}{blue!50}
\colorlet{circle area}{magenta!20}

\tikzset{filled/.style={fill=circle area, draw=circle edge, thick},
    outline/.style={draw=circle edge, thick}}

\begin{frame}
\frametitle{Меры сходства и различия}
\begin{columns}
\begin{column}{6cm}
\begin{tikzpicture}
    
    \only<2> {
    \begin{scope}
        \clip \firstcircle;
        \draw[filled, even odd rule] \firstcircle node {$a$}
                                     \secondcircle;
    \end{scope}
    
    }
    \only<3>{
    \begin{scope}
        \clip \firstcircle;
        \fill[filled] \secondcircle;
        \node at (1, 0) {$c$};
    \end{scope}
    }
    \only<4> {
    \begin{scope}
        \clip \secondcircle;
        \draw[filled, even odd rule] \secondcircle node {$b$}
                                     \firstcircle;
    \end{scope}
    }    
    \draw[outline] \firstcircle node {\only<1,5->{$A$}};
    \only<1, 5->{\node at (1,0) {\small $A\cap B$};};
    \draw[outline] \secondcircle node {\only<1,5->{$B$}};
    \draw \rectangle;
    \node[anchor=south] at (current bounding box.south) {$\Omega$};
\end{tikzpicture}
\\~\\
\begin{tabular}{l|l|l|l}
&  $B$ & $\overline{B}$ & $\sum$ \\ \hline
$A$ & $c$ & $a$ & $a+c$ \\\hline
$\overline{A}$ & $b$ & $d$ & $b+d$ \\\hline
$\sum$ & $b+c$ & $a+d$ & $a+b+c+d$
\end{tabular}
$$
\begin{array}{l}
a=|A-B| \\
b=|B-A| \\
c=|A\cap B| \\
d=|\Omega-A\cup B|
\end{array}
$$


\end{column}
\begin{column}{4cm}
Основные меры:
\begin{itemize}
\item<6-> $\dfrac{c}{a+b+c}$ {\small (Jaccard, 1901)}
\item<7-> $\dfrac{2c}{a+b+2c}$ {\small (Чекановский, 1900; Dice, 1945; S\o rensen, 1948)}
\item<8-> $\dfrac{c}{a+b}$ {\small (Кульчинский, 1927)}
\item<9-> $\dfrac{c}{c+a}, \dfrac{c}{c+b}$ {\small (Шимкевич, 1926; Simpson, 1943)}
\end{itemize}
\end{column}
\end{columns}
\end{frame}
% -----------------------------------------

% --------------- слайд 4 -----------------
\begin{frame}
\frametitle{Примеры вычислений}

\only<1->{
\begin{exampleblock}{Стул и тренога}
Имеют 4 и 3 <<ноги>>  соответственно. Общее число ног $c=3$. Если A -- стул, B -- тренога, то $a=1$ и $b=0$.
\only<2->{
\begin{itemize}
\item<2-> мера Жаккара $J=\dfrac{3}{1+0+3} = 0.75$
\item<3-> мера Дайса $D=\dfrac{2\cdot 3}{1+0+2\cdot 3}=6/7\approx 0.857$  
\item<4-> мера Кульчинского $K = \dfrac{3}{1+0}=3$
\end{itemize}
}
\end{exampleblock}
}
\only<5>{
\begin{alertblock}{Вычисления на R}
\texttt{library(sets)}

\texttt{set\_similarity(set(1,2,3,4),set(1,2,5),method="Jaccard")}

[1] 0.4
\end{alertblock}}
\end{frame}
% -----------------------------------------


% --------------- слайд 5 -----------------
\begin{frame}
\frametitle{Параметризация мер сходства}
\begin{exampleblock}{Двухпараметрическое семейство мер (Б.И. Семкин, 2010):}
$$
\begin{array}{l} K_{\tau;\eta} =\left( \dfrac{K_{\tau}^{\eta}(A,B)+K_{\tau}^{\eta}(B,A)}{2}\right)^{1/\eta},
\\ K_{\tau}(A,B) = \dfrac{|A\cap B|}{(1+\tau)|A|-\tau|A\cap B|},\\
K_{\tau}(B,A) = \dfrac{|A\cap B|}{(1+\tau)|B|-\tau|A\cap B|} \\ -1<\tau<\infty, -\infty<\eta<\infty \end{array}
$$
В этом случае $K_{0;-1}$ и $K_{1;-1}$ совпадают с коэффициентами Сёренсена-Дайса и Жаккара соответственно. 
\end{exampleblock}
\only<2->{
\begin{alertblock}{Вывод}
Используемые меры имеют много общего, они в определенном смысле <<эквивалентны>>
\end{alertblock}
}
\end{frame}
% -----------------------------------------

% --------------- слайд 6 -----------------
\begin{frame}
\frametitle{Точный тест Фишера}
\begin{exampleblock}{Задача}
Исследуется вопрос об эффективности обработки с целью последующего проращивания
жёлудей. В результате эксперимента построена следующая таблица
сопряженности:
\begin{tabular}{l|l|l|l}
&  не взошел & взошел & $\sum$ \\ \hline
обработано & $1$ & $10$ & $11$ \\\hline
не обработано & $4$ & $3$ & $7$ \\\hline
$\sum$ & $5$ & $13$ & $18$
\end{tabular}

Целесообразно ли применение данной обработки, или <<увеличение>> всхожести в результате обработки вполне могло возникнуть случайно?
\end{exampleblock}

\only<2->{
\begin{alertblock}{Решение}
\footnotesize
Нужно вычислить вероятность реализации  таблицы $[(1, 10),(4, 3)]$, а также более <<худшего>> варианта, $[(0,11),(5,2)]$,
т.е. когда после обработки вообще все семена взошли. Если сумма этих вероятностей будет мала, то, вероятно, 
что обработка (а не случайность) определяет исход прорастания.
\end{alertblock}
}

\end{frame}
% -----------------------------------------


% --------------- слайд 7 -----------------
\begin{frame}
\frametitle{Точный тест Фишера}

\only<1-2>{
\begin{exampleblock}{Решение}
\def\arraystretch{2.2}
$$
\begin{array}{l}\dfrac{C^1_{5}\cdot C^{10}_{13}}{C^{11}_{18}}+\dfrac{C^0_5C^{11}_{13}}{C^{11}_{18}} = \\
\dfrac{1430}{31824} + \dfrac{78}{31824}\approx 0.047
\end{array}
$$
\only<2->{Таким образом, вероятность наблюдать исход экспериента, или даже исход, когда все желуди взошли вследствие случая (а не действия
обработки), равна около 4.7\%; это весьма маленькое значение, поэтому результаты наблюдений следует интерпретировать, что имеет
место значимое влияние обработки на результат прорастания желудей.}
\end{exampleblock}
}
\only<3->{
\begin{alertblock}{Общий случай}

\begin{tabular}{l|l|l|l}
&  не взошел & взошел & $\sum$ \\ \hline
обработано & $a$ & $b$ & $a+b$ \\\hline
не обработано & $c$ & $d$ & $c+d$ \\\hline
$\sum$ & $a+c$ & $b+d$ & $a+b+c+d$
\end{tabular}
$$
\begin{array}{l}
P(a,b; c,d) = \dfrac{C^a_{a+c}\cdot C^b_{b+d}}{C_n^{a+b}}=\dfrac{(a+c)!(b+d)!(a+b)!(c+d)!}{a!b!c!d!n!},\\
n = a+b+c+d
\end{array}
$$
\end{alertblock}
}

\only<4>{
\begin{block}{Односторонний тест: <<усугубление>> наблюдаемой ситуации}
$\sum\limits_{j=0}^a P(j, \tilde b; \tilde c, \tilde d)$, при условии: $j+\tilde c = a+c$, $\tilde b + \tilde d= b+d$, $\tilde b + j =a+b$,
$j + \tilde b+\tilde c +\tilde d =n$
\end{block}
}

\only<5->{
\begin{block}{Двусторонний тест\only<6->{: что считать <<усугублением>>?}}
\only<7->{
$\sum\limits_{\tilde a, \tilde b, \tilde c, \tilde d}P(\tilde a, \tilde b; \tilde b,\tilde d)$, суммирование при условиях:
$P(\tilde a, \tilde b; \tilde c, \tilde d)\leq P(a,b;c,d)$,
$\tilde a + \tilde b = a +b$, $\tilde c +\tilde d = c+d$ \ldots
}
\end{block}
}
\end{frame}
% -----------------------------------------


% --------------- слайд 8 -----------------
\begin{frame}
\frametitle{Точный тест Фишера: приближенные вычисления}
\begin{tabular}{l|l|l|l}
&  не взошел & взошел & $\sum$ \\ \hline
обработано & $a$ & $b$ & $a+b$ \\\hline
не обработано & $c$ & $d$ & $c+d$ \\\hline
$\sum$ & $a+c$ & $b+d$ & $a+b+c+d$
\end{tabular}
Гипотеза: наблюдаемое распределение $a,b,c,d$ результат случая

\begin{exampleblock}{Аппроксимация распределением $\chi^2$ (c поправкой Ейтса)}
$$
\begin{array}{l}
\chi^2_{\mbox{выч.}} = \dfrac{n\left(|ad-bc|-\frac{n}{2}\right)^2}{(a+b)(a+c)(b+d)(c+d)} \\
n = a+b+c+d
\end{array}
$$
условия применимости: $a,b,c,d\geq 5, n\geq 40$
\end{exampleblock}
Гипотеза отвергается на уровне значимости $\alpha$, если  $\chi_{\mbox{выч.}}^2>\chi^2_{1-\alpha}(1)$ (в частности, $\chi^2_{0.95}(1)\approx
3.85$, 1 -- число степеней свободы для таблицы $2\times 2$)
\end{frame}
% -----------------------------------------


% --------------- слайд 9 -----------------
\begin{frame}
\frametitle{Задачи классификации}
\begin{itemize}
	\item<1-> Классификация в отсутствии обучающей выборки (кластеризация);
	\item<2-> Классификация при наличии обучающей выборки (по прецедентам); 
 \end{itemize}
\end{frame}
% -----------------------------------------


% --------------- слайд 10 ----------------
\begin{frame}
	\frametitle{Кластеризация}
\begin{itemize}
	\item<1-> Иерархический (агломеративная, дивизивные);	
\item<2-> Логическая кластеризация
\item<3-> Вероятностные
\item<4-> Нейросетевые
\end{itemize}
\end{frame}
% -----------------------------------------


% --------------- слайд 11 ----------------
\begin{frame}
\frametitle{Иерархическая агломеративная кластеризация}
\begin{exampleblock}{Общая структура алгоритмов}
	\begin{itemize}
		\item задание расстояние между кластеризуемыми объектами;
		\item задание расстояние между группами объектов;
	\end{itemize}
\end{exampleblock}


\end{frame}
% -----------------------------------------


% --------------- слайд 12 ----------------
\begin{frame}
\frametitle{Расстояние между объектами}
Полагается, что объекты $x,y$ имеют координаты $x_1,\ldots,x_n$ и $y_1,\ldots,y_n$.
\begin{itemize}
	\item<1-> Евклидово расстояние: $\rho(x, y) =\sum\limits_j(x_j-y_j)^2$;
	\item<2-> Расстояние Чебышева: $\rho(x, y) = \max_j|x_j-y_j|$;
	\item<3-> Расстояние city-block: $\rho(x, y) = \sum\limits_i|x_i-y_i|$;
	\item<4-> Расстояние Минковского: $\rho(x,y)^p=\sum\limits_i(x_i-y_i)^p$;
	\end{itemize}
\end{frame}
% -----------------------------------------


% --------------- слайд 13 ----------------
\begin{frame}
\frametitle{Подходы для вычисления расстояний между группами объектов}
\begin{itemize}
	\item<1-> метод минимального расстояния (single method);
	\item<2-> метод максимального расстояния (complete method);
	\item<3-> попарное среднее;
	\item<4-> центроидный метод;	
\end{itemize}
\end{frame}
% -----------------------------------------


% --------------- слайд 14 ----------------
\begin{frame}
\frametitle{Представление иерархической кластеризации в виде дендрограммы}
\includegraphics[width=11cm]{dendrogram.jpg}
\end{frame}
% -----------------------------------------

% --------------- слайд 15 ----------------
\begin{frame}
\frametitle{Метод k-средних}
\begin{itemize}
	\item задается число кластеров $k$;
	\item в факторном пространстве случайным образом выбираются начальные приближения центров кластеров;
	\item ближайшие к j-му центру точки помещаются в j-й кластер;
	\item пересчитываются центроиды кластеров;
\end{itemize}
Последние 2 шага повторяются пока алгоритм не сойдется.
\end{frame}
% -----------------------------------------

% --------------- слайд 16 ----------------
\begin{frame}
\frametitle{Сравнение кластерных структур}
\begin{exampleblock}{Задача}
	Можно ли построить какую-либо меру, чтобы сравнить, например, кластерные структуры?:
	$$
	\begin{array}{l}
	a,a,a,b,b,c,c,c,c\\
	1,1,1,3,3,2,2,2,2
	\end{array}
	$$
	или
	$$
	\begin{array}{l}
		a,a,a,b,b,c,c,c,c\\
		2,2,2,1,1,3,3,3,1
	\end{array}
	$$
\end{exampleblock}
\end{frame}
% -----------------------------------------

% --------------- слайд 17 ----------------
\begin{frame}
\frametitle{Индекс Рэнда}
Пусть $X=(x_1,\ldots,x_n)$ -- n-элементное множество; $P=(A_1,\ldots, A_r)$ и $Q=(B_1,\ldots,B_s)$ -- два его разбиения.
Определим 
\begin{itemize}
	\item $a$ -- число пар элементов попавших в один кластер в разбиениях $P$ и $Q$ одновременно;
	\item $b$ -- число пар элементов, находящихся в разных кластерах в разбиениях $P$ и $Q$;
	\item $c$ -- число пар элементов, находящихся в одном кластере в $P$ разбиении, но в разных в $Q$;
	\item $d$ -- число пар элементов, находящихся в разных кластерах в $P$ разбиении, но в одном в $Q$;
\end{itemize}
В этом случае $a+b$ -- характеризует степень совпадения кластеров, если $c=d=0$, то кластерные структуры совпадают.
Индекс Рэнда:
$$
I_R = \dfrac{a+b}{a+b+c+d} = \dfrac{a+b}{C_n^2}
$$
\end{frame}
% -----------------------------------------


